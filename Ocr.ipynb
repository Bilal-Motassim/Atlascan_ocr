{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9c3286cb-a052-46bb-b4e6-ed35c10f557b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/12/29 15:10:04] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='C:\\\\Users\\\\pc/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='C:\\\\Users\\\\pc/.paddleocr/whl\\\\rec\\\\latin\\\\latin_PP-OCRv3_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='C:\\\\Users\\\\pc\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python312\\\\Lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\dict\\\\latin_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='C:\\\\Users\\\\pc/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='fr', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2024/12/29 15:10:08] ppocr DEBUG: dt_boxes num : 19, elapsed : 0.2720973491668701\n",
      "[2024/12/29 15:10:08] ppocr DEBUG: cls num  : 19, elapsed : 0.1091609001159668\n",
      "[2024/12/29 15:10:08] ppocr DEBUG: rec_res num  : 19, elapsed : 0.3810243606567383\n",
      "\n",
      "Sure! Here is the structured data extracted from the given text:\n",
      "\n",
      "{\n",
      "\"Prénom\": \"Hamza\",\n",
      "\"Nom de famille\": \"El Bouzidi\",\n",
      "\"Date de naissance\": \"29.11.2001\",\n",
      "\"Lieu de naissance\": \"Néle\",\n",
      "\"Num d'identité\": \"CAN613945\",\n",
      "\"Valable jusqu'au\": \"26.05.2031\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "import ollama\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "# Initialize the OCR model with French language support\n",
    "ocr = PaddleOCR(use_angle_cls=True, lang='fr')  # Use French language for OCR\n",
    "\n",
    "# Function to generate structured data from text using Llama 2 through Ollama\n",
    "def generate_structured_data_from_text_with_ollama(raw_text):\n",
    "    # Create a prompt for Llama 2 via Ollama (no detailed explanations, just output the structured data)\n",
    "    prompt = f\"Given the following text from an ID card, extract the structured data:\\n\\n{raw_text}\\n\\nPlease extract and return a JSON with: Prénom, Nom de famille, Date de naissance, Lieu de naissance, Num d'identité, and Valable jusqu'au. Do not include explanations, just and only output the JSON.\"\n",
    "\n",
    "    # Use Ollama to call Llama 2\n",
    "    response = ollama.chat(model=\"llama2:latest\", messages=[{\"role\": \"user\", \"content\": prompt}])\n",
    "    \n",
    "    # Extract the structured data from the assistant's response (ignore other details)\n",
    "    structured_data_content = response.get('message', {}).get('content', '')\n",
    "    \n",
    "    # Return the structured data as a string (it should be in JSON format)\n",
    "    return structured_data_content\n",
    "\n",
    "# Function to perform OCR and extract structured data based on Llama 2 assistance\n",
    "def extract_semantic_data_with_ollama(image_path):\n",
    "    # Perform OCR directly on the image\n",
    "    result = ocr.ocr(image_path, cls=True)\n",
    "    \n",
    "    # Flatten the OCR result to get the list of detected text lines\n",
    "    extracted_text = [line[1][0] for line in result[0]]\n",
    "    \n",
    "    # Join all extracted text into a single string for Llama 2 to process\n",
    "    raw_text = \"\\n\".join(extracted_text)\n",
    "    \n",
    "    # Generate structured data using Llama 2 via Ollama\n",
    "    structured_data = generate_structured_data_from_text_with_ollama(raw_text)\n",
    "    \n",
    "    # Return the structured data (in JSON format as a string)\n",
    "    return structured_data\n",
    "\n",
    "# Path to the original image\n",
    "image_path = \"cin.jpg\"\n",
    "\n",
    "# Extract and display the semantic data from the image using Llama 2 via Ollama\n",
    "structured_data = extract_semantic_data_with_ollama(image_path)\n",
    "\n",
    "# Print the structured data as it is (without the metadata)\n",
    "print(structured_data)\n",
    "\n",
    "# Optionally, save the structured data to a file\n",
    "with open(\"structured_data.json\", \"w\") as f:\n",
    "    # Write the structured data (as a string) to the file\n",
    "    f.write(structured_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
